{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bartpho_test.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPCOm4szwUmkJ5fLvJDUlwp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c4187cd77a154444ad0eda8f07825598":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d0b55fb7a0c2419ca0a8244982c4850e","IPY_MODEL_a89e866416564dcfb063b37952fe80a1","IPY_MODEL_d8182cbd23f949a9b277522d2e39cb70"],"layout":"IPY_MODEL_f525621a81464ccba4fbbafa8a7d08d3"}},"d0b55fb7a0c2419ca0a8244982c4850e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcbf26c0a60b4a6a935a1a87f0126dba","placeholder":"​","style":"IPY_MODEL_fb2023f0e2754e9bb1b195ba49dc6d6b","value":"Downloading: 100%"}},"a89e866416564dcfb063b37952fe80a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb7b61426fb94524bd37d9351066c42e","max":866,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d48d71a298b34e78a96973ac1802945b","value":866}},"d8182cbd23f949a9b277522d2e39cb70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb294e6942604ef58e4a6b0ef0228569","placeholder":"​","style":"IPY_MODEL_ec93748617a240edabf3c31b32a8e95e","value":" 866/866 [00:00&lt;00:00, 14.7kB/s]"}},"f525621a81464ccba4fbbafa8a7d08d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcbf26c0a60b4a6a935a1a87f0126dba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb2023f0e2754e9bb1b195ba49dc6d6b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb7b61426fb94524bd37d9351066c42e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d48d71a298b34e78a96973ac1802945b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fb294e6942604ef58e4a6b0ef0228569":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec93748617a240edabf3c31b32a8e95e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16d698740fe24911897385aa154b675a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_72105f7ff4f0428584d727a5fe2223b0","IPY_MODEL_d158e938549a4f7293d99c7cca4d4abe","IPY_MODEL_3387d485d3f54e0b9f5b4e5d384bb97c"],"layout":"IPY_MODEL_ec0a214ef417448eb4b53c3eaf0cec6b"}},"72105f7ff4f0428584d727a5fe2223b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95663f71217a47e29b3328e5413082f6","placeholder":"​","style":"IPY_MODEL_9c3dfb5a1add414783710ce094db6c0b","value":"Downloading: 100%"}},"d158e938549a4f7293d99c7cca4d4abe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d0701b766914710ba0ca89f58ba9630","max":895321,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf59746df9f64ba9af55751e6c6ca7d1","value":895321}},"3387d485d3f54e0b9f5b4e5d384bb97c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d669a79e2e047f2a47121a8a18b0b14","placeholder":"​","style":"IPY_MODEL_5182bb6092824690801a19d41b54535c","value":" 874k/874k [00:00&lt;00:00, 1.68MB/s]"}},"ec0a214ef417448eb4b53c3eaf0cec6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95663f71217a47e29b3328e5413082f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c3dfb5a1add414783710ce094db6c0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d0701b766914710ba0ca89f58ba9630":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf59746df9f64ba9af55751e6c6ca7d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9d669a79e2e047f2a47121a8a18b0b14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5182bb6092824690801a19d41b54535c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21a31f3a9f414456a5da450e7da46d9a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f48c4ffe9eca414391214ab5a66274c8","IPY_MODEL_be051ce85f2a40ff860b7a9ef7f30242","IPY_MODEL_5ded244ff5aa4e1296ff98d47fe06fc6"],"layout":"IPY_MODEL_fc48bb33a0174b4a98bf56e5e4f88eb5"}},"f48c4ffe9eca414391214ab5a66274c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd5f5d312a9748f097ee359d4f7b17e6","placeholder":"​","style":"IPY_MODEL_0aa8802aba0c43e7a048987604833fa8","value":"Downloading: 100%"}},"be051ce85f2a40ff860b7a9ef7f30242":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a1f13ecd53f4de4966f0fcc3bc40738","max":1135173,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b0616f901c341a784bfad7b8a882f82","value":1135173}},"5ded244ff5aa4e1296ff98d47fe06fc6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65231e5264f143bc9a357006d7ddffe6","placeholder":"​","style":"IPY_MODEL_dab1459b9d904da2aab6b010564bc878","value":" 1.08M/1.08M [00:00&lt;00:00, 1.61MB/s]"}},"fc48bb33a0174b4a98bf56e5e4f88eb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd5f5d312a9748f097ee359d4f7b17e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0aa8802aba0c43e7a048987604833fa8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a1f13ecd53f4de4966f0fcc3bc40738":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b0616f901c341a784bfad7b8a882f82":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"65231e5264f143bc9a357006d7ddffe6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dab1459b9d904da2aab6b010564bc878":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf1710ec7fe34db1bd2da276aa23cea6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5fbe16af4bd8474eb0a3e96b14aceb26","IPY_MODEL_ccec5488a7b441b58451cc8cb551c36a","IPY_MODEL_52ff6e97f4754513a21f97147c64c173"],"layout":"IPY_MODEL_b36a03a7565d469cae4d4d7e8d6ab01c"}},"5fbe16af4bd8474eb0a3e96b14aceb26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e0d61374a014188a89f99e0843eb7dc","placeholder":"​","style":"IPY_MODEL_d1fb512d0ca549f996f6784a7eaf9594","value":"Downloading: 100%"}},"ccec5488a7b441b58451cc8cb551c36a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3eecea66623341ed8585706638e7c8f6","max":1681637133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1d244e0620ed4e199d3818349f694aa8","value":1681637133}},"52ff6e97f4754513a21f97147c64c173":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02cb30983d334319acf6325433ea6f32","placeholder":"​","style":"IPY_MODEL_063fd7884e894aaf93dac616848bfad6","value":" 1.57G/1.57G [00:39&lt;00:00, 33.6MB/s]"}},"b36a03a7565d469cae4d4d7e8d6ab01c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e0d61374a014188a89f99e0843eb7dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1fb512d0ca549f996f6784a7eaf9594":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3eecea66623341ed8585706638e7c8f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d244e0620ed4e199d3818349f694aa8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"02cb30983d334319acf6325433ea6f32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"063fd7884e894aaf93dac616848bfad6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["pip install galore (Your boring dependency installation)"],"metadata":{"id":"Y4yfNAUUqFhf"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r7WNGRXNPr46","executionInfo":{"status":"ok","timestamp":1653215939379,"user_tz":-420,"elapsed":29021,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}},"outputId":"4d56b3d4-0f8d-4fb6-baf3-9ef95a663607"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting vncorenlp\n","  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vncorenlp) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (3.0.4)\n","Building wheels for collected packages: vncorenlp\n","  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645951 sha256=6a1a0f519bfca94b0fb0994d55e736cad52c6db07239ad39c7713bbf406358eb\n","  Stored in directory: /root/.cache/pip/wheels/0c/d8/f2/d28d97379b4f6479bf51247c8dfd57fa00932fa7a74b6aab29\n","Successfully built vncorenlp\n","Installing collected packages: vncorenlp\n","Successfully installed vncorenlp-1.0.3\n","Collecting transformers\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 33.8 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n","\u001b[K     |████████████████████████████████| 84 kB 3.1 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 34.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 4.1 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Collecting pytorch-lightning\n","  Downloading pytorch_lightning-1.6.3-py3-none-any.whl (584 kB)\n","\u001b[K     |████████████████████████████████| 584 kB 4.8 MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.8.0)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.3)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.21.6)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (6.0)\n","Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.11.0+cu113)\n","Collecting torchmetrics>=0.4.1\n","  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\n","\u001b[K     |████████████████████████████████| 409 kB 47.0 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.2.0)\n","Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 56.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.64.0)\n","Collecting pyDeprecate<0.4.0,>=0.3.1\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 46.5 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (57.4.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.46.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.3)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.7)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.2.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.12)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.4.0)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 65.4 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 62.5 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.4 MB/s \n","\u001b[?25hInstalling collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyDeprecate, fsspec, aiohttp, torchmetrics, pytorch-lightning\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.3 torchmetrics-0.8.2 yarl-1.7.2\n"]}],"source":["!pip3 install vncorenlp\n","!pip3 install transformers\n","!pip3 install sentencepiece\n","!pip3 install pytorch-lightning"]},{"cell_type":"markdown","source":["Download VNCoreNLP (word segmenter feature only)"],"metadata":{"id":"nNkauWyCqN4S"}},{"cell_type":"code","source":["!mkdir -p VnCoreNLP/models/wordsegmenter\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n","!mv VnCoreNLP-1.1.1.jar VnCoreNLP/ \n","!mv vi-vocab VnCoreNLP/models/wordsegmenter/\n","!mv wordsegmenter.rdr VnCoreNLP/models/wordsegmenter/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nRM6ojaMQSvG","executionInfo":{"status":"ok","timestamp":1653215940677,"user_tz":-420,"elapsed":1307,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}},"outputId":"af66be8d-f28e-440c-b18e-8fb9081bcb01"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-05-22 10:38:59--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 27412575 (26M) [application/octet-stream]\n","Saving to: ‘VnCoreNLP-1.1.1.jar’\n","\n","VnCoreNLP-1.1.1.jar 100%[===================>]  26.14M   163MB/s    in 0.2s    \n","\n","2022-05-22 10:38:59 (163 MB/s) - ‘VnCoreNLP-1.1.1.jar’ saved [27412575/27412575]\n","\n","--2022-05-22 10:38:59--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 526544 (514K) [application/octet-stream]\n","Saving to: ‘vi-vocab’\n","\n","vi-vocab            100%[===================>] 514.20K  --.-KB/s    in 0.04s   \n","\n","2022-05-22 10:39:00 (12.3 MB/s) - ‘vi-vocab’ saved [526544/526544]\n","\n","--2022-05-22 10:39:00--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 128508 (125K) [text/plain]\n","Saving to: ‘wordsegmenter.rdr’\n","\n","wordsegmenter.rdr   100%[===================>] 125.50K  --.-KB/s    in 0.02s   \n","\n","2022-05-22 10:39:00 (5.71 MB/s) - ‘wordsegmenter.rdr’ saved [128508/128508]\n","\n"]}]},{"cell_type":"markdown","source":["Mount my Google Drive to this machine (To load training data and save/load checkpoint)"],"metadata":{"id":"1qQxXO5Bqhue"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=False)\n","root_dir = \"/content/gdrive/MyDrive/\"\n","base_dir = root_dir + 'ElainaModel/'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RQDE30IytSlR","executionInfo":{"status":"ok","timestamp":1653215961975,"user_tz":-420,"elapsed":21306,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}},"outputId":"4146a942-4c6b-476e-ce6f-f724ce05b6d5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["Now the fun bit (Setting up the model as a PyTorch Lightning model)"],"metadata":{"id":"B-3zaukLqwW9"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoModel, AutoTokenizer\n","from transformers import MBartForConditionalGeneration, AdamW, BartConfig, BartTokenizer, MBartTokenizer\n","from vncorenlp import VnCoreNLP\n","\n","from torch.utils.data import DataLoader, TensorDataset, random_split, RandomSampler, Dataset\n","import pandas as pd\n","import numpy as np\n","\n","import torch.nn.functional as F\n","import pytorch_lightning as lightning\n","import torch\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","\n","import math\n","import random\n","import re\n","import argparse\n","\n","class ElainaModel(lightning.LightningModule):\n","    def __init__(self, learning_rate, tokenizer, model, hparams):\n","      super().__init__()\n","      self.tokenizer = tokenizer\n","      self.model = model\n","      self.learning_rate = learning_rate\n","      # self.freeze_encoder = freeze_encoder\n","      # self.freeze_embeds_ = freeze_embeds\n","      self.hparams.update(hparams)\n","\n","      if self.hparams.freeze_encoder:\n","        freeze_params(self.model.get_encoder())\n","\n","      if self.hparams.freeze_embeds:\n","        self.freeze_embeds()\n","\n","      print('constructor end')\n","    \n","    def freeze_embeds(self):\n","      ''' freeze the positional embedding parameters of the model; adapted from finetune.py '''\n","      freeze_params(self.model.model.shared)\n","      for d in [self.model.model.encoder, self.model.model.decoder]:\n","        freeze_params(d.embed_positions)\n","        freeze_params(d.embed_tokens)\n","\n","    # Do a forward pass through the model\n","    def forward(self, input_ids, **kwargs):\n","      return self.model(input_ids, **kwargs)\n","    \n","    def configure_optimizers(self):\n","      optimizer = torch.optim.Adam(self.parameters(), lr = self.learning_rate)\n","      return optimizer\n","\n","    def training_step(self, batch, batch_idx):\n","      # Load the data into variables\n","      src_ids, src_mask = batch[0], batch[1]\n","      tgt_ids = batch[2]\n","      # Shift the decoder tokens right (but NOT the tgt_ids)\n","      # replaced tokenizer with self.tokenizer\n","      decoder_input_ids = shift_tokens_right(tgt_ids, self.tokenizer.pad_token_id)\n","\n","      # Run the model and get the logits\n","      outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n","      lm_logits = outputs[0]\n","      # Create the loss function\n","      ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n","      # Calculate the loss on the un-shifted tokens\n","      loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n","\n","      return {'loss':loss}\n","\n","    def validation_step(self, batch, batch_idx):\n","\n","      src_ids, src_mask = batch[0], batch[1]\n","      tgt_ids = batch[2]\n","\n","      # replaced tokenizer with self.tokenizer\n","      decoder_input_ids = shift_tokens_right(tgt_ids, self.tokenizer.pad_token_id)\n","      \n","      # Run the model and get the logits\n","      outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n","      lm_logits = outputs[0]\n","\n","      ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n","      val_loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n","\n","      return {'loss': val_loss}\n","    \n","    # Method that generates text using the BartForConditionalGeneration's generate() method\n","    def generate_text(self, text, eval_beams, early_stopping = True, max_len = 40):\n","      ''' Function to generate text '''\n","      generated_ids = self.model.generate(\n","          text[\"input_ids\"],\n","          attention_mask=text[\"attention_mask\"],\n","          use_cache=True,\n","          decoder_start_token_id = self.tokenizer.pad_token_id,\n","          num_beams= eval_beams,\n","          max_length = max_len,\n","          early_stopping = early_stopping\n","      )\n","      return [self.tokenizer.decode(w, skip_special_tokens=True, clean_up_tokenization_spaces=True) for w in generated_ids]\n","\n","def freeze_params(model):\n","  ''' Function that takes a model as input (or part of a model) and freezes the layers for faster training\n","      adapted from finetune.py '''\n","  for layer in model.parameters():\n","    layer.requires_grade = False\n","\n","def shift_tokens_right(input_ids, pad_token_id):\n","  \"\"\" Shift input ids one token to the right, and wrap the last non pad token (usually <eos>).\n","      This is taken directly from modeling_bart.py\n","  \"\"\"\n","  prev_output_tokens = input_ids.clone()\n","  index_of_eos = (input_ids.ne(pad_token_id).sum(dim=1) - 1).unsqueeze(-1)\n","  prev_output_tokens[:, 0] = input_ids.gather(1, index_of_eos).squeeze()\n","  prev_output_tokens[:, 1:] = input_ids[:, :-1]\n","  return prev_output_tokens\n","\n"],"metadata":{"id":"k0-10-AGQlke","executionInfo":{"status":"ok","timestamp":1653215969028,"user_tz":-420,"elapsed":7060,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Sentence enconding function to turn all text things into number things (using BART's tokenizer)"],"metadata":{"id":"D8N-d7Ndq9U5"}},{"cell_type":"code","source":["def encode_sentences(tokenizer, source_sentences, target_sentences, max_length=32, pad_to_max_length=True, return_tensors=\"pt\", rdrsegmenter=None):\n","  ''' Function that tokenizes a sentence \n","      Args: tokenizer - the BART tokenizer; source and target sentences are the source and target sentences\n","      Returns: Dictionary with keys: input_ids, attention_mask, target_ids\n","  '''\n","\n","  input_ids = []\n","  attention_masks = []\n","  target_ids = []\n","  tokenized_sentences = {}\n","\n","  for sentence in source_sentences:\n","    if rdrsegmenter is not None:\n","      seg_sentence = rdrsegmenter.tokenize(sentence)\n","      seg_sentence = ' '.join([' '.join(x) for x in seg_sentence])\n","    else:\n","      seg_sentence = sentence\n","    encoded_dict = tokenizer(\n","          seg_sentence,\n","          max_length=max_length,\n","          padding=\"max_length\" if pad_to_max_length else None,\n","          truncation=True,\n","          return_tensors=return_tensors,\n","          # add_prefix_space = True\n","      )\n","\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","  input_ids = torch.cat(input_ids, dim = 0)\n","  attention_masks = torch.cat(attention_masks, dim = 0)\n","\n","  for sentence in target_sentences:\n","    if rdrsegmenter is not None:\n","      seg_sentence = rdrsegmenter.tokenize(sentence)\n","      seg_sentence = ' '.join([' '.join(x) for x in seg_sentence])\n","    else:\n","      seg_sentence = sentence\n","    encoded_dict = tokenizer(\n","          seg_sentence,\n","          max_length=max_length,\n","          padding=\"max_length\" if pad_to_max_length else None,\n","          truncation=True,\n","          return_tensors=return_tensors,\n","          # add_prefix_space = True\n","      )\n","    # Shift the target ids to the right\n","    # shifted_target_ids = shift_tokens_right(encoded_dict['input_ids'], tokenizer.pad_token_id)\n","    target_ids.append(encoded_dict['input_ids'])\n","\n","  target_ids = torch.cat(target_ids, dim = 0)\n","  \n","\n","  batch = {\n","      \"input_ids\": input_ids,\n","      \"attention_mask\": attention_masks,\n","      \"labels\": target_ids,\n","  }\n","\n","  return batch"],"metadata":{"id":"slBB7YsQtxhn","executionInfo":{"status":"ok","timestamp":1653215969028,"user_tz":-420,"elapsed":9,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Data loading class where we get the .csv file and (after the totally optional word segmenting task) get encoded into tensors (lots of'em)"],"metadata":{"id":"Z4crNYqQrMz_"}},{"cell_type":"code","source":["# Create a dataloading module as per the PyTorch Lightning Docs\n","class SummaryDataModule(lightning.LightningDataModule):\n","  def __init__(self, tokenizer, data_file, batch_size, num_examples = 20000, use_segmenter = False):\n","    super().__init__()\n","    self.tokenizer = tokenizer\n","    self.data_file = data_file\n","    self.batch_size = batch_size\n","    self.num_examples = num_examples\n","\n","    if use_segmenter:\n","      self.rdrsegmenter = VnCoreNLP(\"./VnCoreNLP/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')\n","    else:\n","      self.rdrsegmenter = None\n","  \n","  # Loads and splits the data into training, validation and test sets with a 60/20/20 split\n","  def prepare_data(self):\n","    self.data = pd.read_csv(self.data_file)[:self.num_examples]\n","    self.train, self.validate, self.test = np.split(self.data.sample(frac=1), [int(.6*len(self.data)), int(.8*len(self.data))])\n","\n","  # encode the sentences using the tokenizer  \n","  def setup(self, stage):\n","    self.train = encode_sentences(self.tokenizer, self.train['source'], self.train['target'], rdrsegmenter = self.rdrsegmenter)\n","    self.validate = encode_sentences(self.tokenizer, self.validate['source'], self.validate['target'], rdrsegmenter = self.rdrsegmenter)\n","    self.test = encode_sentences(self.tokenizer, self.test['source'], self.test['target'], rdrsegmenter = self.rdrsegmenter)\n","\n","  # Load the training, validation and test sets in Pytorch Dataset objects\n","  def train_dataloader(self):\n","    dataset = TensorDataset(self.train['input_ids'], self.train['attention_mask'], self.train['labels'])                          \n","    train_data = DataLoader(dataset, sampler = RandomSampler(dataset), batch_size = self.batch_size)\n","    return train_data\n","\n","  def val_dataloader(self):\n","    dataset = TensorDataset(self.validate['input_ids'], self.validate['attention_mask'], self.validate['labels']) \n","    val_data = DataLoader(dataset, batch_size = self.batch_size)                       \n","    return val_data\n","\n","  def test_dataloader(self):\n","    dataset = TensorDataset(self.test['input_ids'], self.test['attention_mask'], self.test['labels']) \n","    test_data = DataLoader(dataset, batch_size = self.batch_size)                   \n","    return test_data\n"],"metadata":{"id":"-ak7y14DSA9x","executionInfo":{"status":"ok","timestamp":1653215969029,"user_tz":-420,"elapsed":7,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["The part where we can acually use our model which include the noise generator for less predictable behavior and the generation function"],"metadata":{"id":"5jJjuDKlrmRU"}},{"cell_type":"code","source":["\n","def noise_sentence(sentence_, percent_words, replacement_token = \"<mask>\"):\n","  '''\n","  Function that noises a sentence by adding <mask> tokens\n","  Args: sentence - the sentence to noise\n","        percent_words - the percent of words to replace with <mask> tokens; the number is rounded up using math.ceil\n","  Returns a noised sentence\n","  '''\n","  # Create a list item and copy\n","  sentence_ = sentence_.split(' ')\n","  sentence = sentence_.copy()\n","  \n","  num_words = math.ceil(len(sentence) * percent_words)\n","  \n","  # Create an array of tokens to sample from; don't include the last word as an option because in the case of lyrics\n","  # that word is often a rhyming word and plays an important role in song construction\n","  sample_tokens = set(np.arange(0, np.maximum(1, len(sentence)-1)))\n","  \n","  words_to_noise = random.sample(sample_tokens, num_words)\n","  \n","  # Swap out words, but not full stops\n","  for pos in words_to_noise:\n","      if sentence[pos] != '.':\n","          sentence[pos] = replacement_token\n","  \n","  # Remove redundant spaces\n","  sentence = re.sub(r' {2,5}', ' ', ' '.join(sentence))\n","  \n","  # Combine concurrent <mask> tokens into a single token; this just does two rounds of this; more could be done\n","  sentence = re.sub(r'<mask> <mask>', \"<mask>\", sentence)\n","  sentence = re.sub(r'<mask> <mask>', \"<mask>\", sentence)\n","  return sentence\n","\n","def generate_response(seed_line, num_lines, model_, noise_percent = 0.25, multiple_lines = False, max_line_history = 3, rdrsegmenter = None):\n","  ''' Function that generates lyrics based on previously generated lyrics \n","      Args: seed_line - a line to start off the machine\n","            num_lines - the number of lines to generate\n","            model_ - the model used to generate the text\n","            multiple_lines - whether the model generates based on multiple previous lines or just the past line\n","            max_line_history - the maximum number of previous lines used in the current input\n","      Returns a list with num_lines of rap lines\n","  '''\n","  # Put the model on eval mode\n","  model_.to(torch.device('cpu'))\n","  model_.eval()\n","  if rdrsegmenter is not None:\n","    seed_line = ' '.join([' '.join(x) for x in rdrsegmenter.tokenize(seed_line)])\n","  dialog = []\n","  dialog.append(seed_line)\n","  # not using noise gen here, lets see if it works\n","  prompt_line_tokens = tokenizer(noise_sentence(seed_line, noise_percent), max_length = 32, return_tensors = \"pt\", truncation = True)\n","  # Loop through the number of lines generating a new line based on the old\n","\n","  line = [seed_line]\n","  for i in range(num_lines):\n","    # Print out the new line\n","    entry = line[0].strip().replace('< s >', '').replace('< / s >', '')\n","    # print(entry)\n","    dialog.append(entry)\n","    line = model.generate_text(prompt_line_tokens, eval_beams = 4)\n","    # This deals with an artefact in the training data that I had an issue cleaning\n","    if line[0].find(\":\") != -1:\n","      line[0] = re.sub(r'[A-Z]+: ', '', line[0])\n","    # This allows the model to generate a new line conditioned on more than one line\n","    if multiple_lines:\n","      start_line = np.maximum(0, i - max_line_history)\n","      end_line = i\n","      prompt_line = ' '.join(dialog[start_line:end_line]) # Going to end_line is fine because it is non-inclusive\n","    else:\n","      prompt_line = dialog[i]\n","    # not using noise gen here, lets see if it works\n","    prompt_line_tokens = tokenizer(noise_sentence(prompt_line, noise_percent), max_length = 32, return_tensors = \"pt\", truncation = True)\n","\n","  return dialog"],"metadata":{"id":"9SDp_ym2FAx_","executionInfo":{"status":"ok","timestamp":1653216880570,"user_tz":-420,"elapsed":348,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["This is the main function, we first setup our tokenizer and base BARTPho model"],"metadata":{"id":"qElo_gdAsLuL"}},{"cell_type":"code","source":["hparams = {\n","    'freeze_encoder': True,\n","    'freeze_embeds': True,\n","    'eval_beams': 4\n","}\n","\n","print('Setting up tokenizer...')\n","tokenizer = AutoTokenizer.from_pretrained('vinai/bartpho-word')\n","\n","print('Setting up BARTPho pretrained model...')\n","bart_model = MBartForConditionalGeneration.from_pretrained('vinai/bartpho-word')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217,"referenced_widgets":["c4187cd77a154444ad0eda8f07825598","d0b55fb7a0c2419ca0a8244982c4850e","a89e866416564dcfb063b37952fe80a1","d8182cbd23f949a9b277522d2e39cb70","f525621a81464ccba4fbbafa8a7d08d3","bcbf26c0a60b4a6a935a1a87f0126dba","fb2023f0e2754e9bb1b195ba49dc6d6b","bb7b61426fb94524bd37d9351066c42e","d48d71a298b34e78a96973ac1802945b","fb294e6942604ef58e4a6b0ef0228569","ec93748617a240edabf3c31b32a8e95e","16d698740fe24911897385aa154b675a","72105f7ff4f0428584d727a5fe2223b0","d158e938549a4f7293d99c7cca4d4abe","3387d485d3f54e0b9f5b4e5d384bb97c","ec0a214ef417448eb4b53c3eaf0cec6b","95663f71217a47e29b3328e5413082f6","9c3dfb5a1add414783710ce094db6c0b","3d0701b766914710ba0ca89f58ba9630","bf59746df9f64ba9af55751e6c6ca7d1","9d669a79e2e047f2a47121a8a18b0b14","5182bb6092824690801a19d41b54535c","21a31f3a9f414456a5da450e7da46d9a","f48c4ffe9eca414391214ab5a66274c8","be051ce85f2a40ff860b7a9ef7f30242","5ded244ff5aa4e1296ff98d47fe06fc6","fc48bb33a0174b4a98bf56e5e4f88eb5","dd5f5d312a9748f097ee359d4f7b17e6","0aa8802aba0c43e7a048987604833fa8","6a1f13ecd53f4de4966f0fcc3bc40738","2b0616f901c341a784bfad7b8a882f82","65231e5264f143bc9a357006d7ddffe6","dab1459b9d904da2aab6b010564bc878","bf1710ec7fe34db1bd2da276aa23cea6","5fbe16af4bd8474eb0a3e96b14aceb26","ccec5488a7b441b58451cc8cb551c36a","52ff6e97f4754513a21f97147c64c173","b36a03a7565d469cae4d4d7e8d6ab01c","7e0d61374a014188a89f99e0843eb7dc","d1fb512d0ca549f996f6784a7eaf9594","3eecea66623341ed8585706638e7c8f6","1d244e0620ed4e199d3818349f694aa8","02cb30983d334319acf6325433ea6f32","063fd7884e894aaf93dac616848bfad6"]},"id":"9XM9A1RSV8tY","executionInfo":{"status":"ok","timestamp":1653216017409,"user_tz":-420,"elapsed":48386,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}},"outputId":"4f535006-98d6-4dfb-8960-1c7884880870"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting up tokenizer...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/866 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4187cd77a154444ad0eda8f07825598"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/874k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16d698740fe24911897385aa154b675a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21a31f3a9f414456a5da450e7da46d9a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["Setting up BARTPho pretrained model...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.57G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf1710ec7fe34db1bd2da276aa23cea6"}},"metadata":{}}]},{"cell_type":"markdown","source":["Select whether you want to train a new model or use a saved model (once you train a new model, make sure you have a bucket ton of RAM)"],"metadata":{"id":"bpPlHzxPsVEL"}},{"cell_type":"code","source":["do_train = input(\"Bạn muốn huấn luyện mô hình mới hay không? (y/n):\")\n","\n","if do_train == 'y':\n","  print(\"Setting up training / validating data...\")\n","  summary_data = SummaryDataModule(tokenizer, \n","                                  data_file='/content/gdrive/MyDrive/ElainaModel/bart_data.csv',\n","                                  batch_size = 8, num_examples = 2744, use_segmenter = True)\n","\n","  print(\"Initializing new model...\")\n","  model = ElainaModel(\n","      learning_rate = 2e-5, \n","      tokenizer = tokenizer, \n","      model = bart_model, \n","      hparams = hparams,\n","  )\n","\n","  checkpoint = ModelCheckpoint(dirpath=base_dir + 'checkpoint_files/')\n","  print(\"Setting up trainer...\")\n","  trainer = lightning.Trainer(\n","      gpus = 1,\n","      max_epochs = 5,\n","      min_epochs = 1,\n","      auto_lr_find = False,\n","      checkpoint_callback = checkpoint,\n","      progress_bar_refresh_rate = 500\n","  )\n","\n","  print(\"Initiate training process.\")\n","  # Prone to Out of Memory error\n","  trainer.fit(model, summary_data)\n","else:\n","  filename = \"checkpoint_files/epoch=4-step=1030.ckpt\"\n","\n","  print(\"Loading checkpoint for fine-tuned model\")\n","  model = ElainaModel.load_from_checkpoint(\n","    base_dir + filename, \n","    learning_rate = 2e-5, \n","    tokenizer = tokenizer, \n","    model = bart_model, \n","    hparams = hparams\n","  )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NoAKR4ecJeWU","executionInfo":{"status":"ok","timestamp":1653216697358,"user_tz":-420,"elapsed":27681,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}},"outputId":"b68395e2-cf1e-4131-812f-2d94e39af62d"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Bạn muốn huấn luyện mô hình mới hay không? (y/n):n\n","Loading checkpoint for fine-tuned model\n","constructor end\n"]}]},{"cell_type":"markdown","source":["Explained in the comment"],"metadata":{"id":"AuWsiXUHsjYI"}},{"cell_type":"code","source":["# uncomment this line to backup trained checkpoints\n","\n","# !cp lightning_logs/version_0/checkpoints/epoch=4-step=1030.ckpt gdrive/MyDrive/ElainaModel/checkpoint_files"],"metadata":{"id":"K9-2isX_DDGF","executionInfo":{"status":"ok","timestamp":1653216558372,"user_tz":-420,"elapsed":28171,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["This is where we can actually test our poor model"],"metadata":{"id":"RvxUBus3sm0j"}},{"cell_type":"code","source":["# testing env\n","\n","rdrsegmenter = VnCoreNLP(\"./VnCoreNLP/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')\n","\n","message = \"\"\n","while message != \"exit\":\n","  message = input(\">>> \")\n","  if message == \"exit\": \n","    continue\n","  new_dialog = generate_response(seed_line = message, num_lines = 2, model_ = model,\n","                           noise_percent = 0, multiple_lines = False, max_line_history = 1, rdrsegmenter=rdrsegmenter)\n","  print(new_dialog[2].replace(\"_\", \" \"))\n","  \n","print(\"Testing stopped\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FrBNCWvSFlr1","executionInfo":{"status":"ok","timestamp":1653217188191,"user_tz":-420,"elapsed":299563,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}},"outputId":"89d81b97-95c8-4521-ad3d-4d0ecb3e27d4"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":[">>> chào bạn\n","Xin chào \n",">>> bạn khỏe chứ\n","Tôi thây vui lắm \n",">>> Thế còn sức khỏe của bạn\n","Thế còn sức khoẻ của tôi? Tôi có khá nhiều đấy. Không muốn liệt kê hết ra đâu \n",">>> Ý bạn là gì\n"," Tôi là trợ lý ảo, không phải người thật \n",">>> Không sao cả, bạn trông khá thật với tôi\n","Không sao đâu, ai cũng có lúc như vậy mà \n",">>> À chắc bạn cũng không cần được an ủi\n","À chắc là tôi không có ý đó. Tôi sẽ hỏi nhà phát triển làm cho tôi ít phiền phức hơn : ( \n",">>> Ừm, hôm nay trời mưa không nhỉ\n","Ừm. Tôi có thể giúp bạn xem thời tiết nếu bạn cần \n",">>> Làm thế nào để xem thời tiết\n","Làm thế nào để xem thời tiết? Tôi có thể giúp gì cho bạn \n",">>> Tôi cần trợ giúp. Làm thế nào để tra cứu thời tiết\n","Tôi sẽ giúp bạn tra cứu thời tiết nhé : ) \n",">>> Okay, cảm ơn bạn\n","Okay. Đó là niềm hân hạnh của tôi được giúp đỡ bạn \n",">>> Bạn cảm thấy thế nào\n","Tôi đang rất vui \n",">>> Vui đến mức nào\n","Tôi rất vui. Có thật nhiều điều thú vị ngoài kia \n",">>> Tôi hiểu rồi. Vậy chào tạm biệt nhé\n","Tôi sẽ nhớ bạn lắm \n",">>> exit\n","Testing stopped\n"]}]}]}